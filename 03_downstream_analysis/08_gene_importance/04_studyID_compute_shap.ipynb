{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "RUN_NAME: str = \"studyID\"\n",
    "CELL_TYPE: str = 'DC'\n",
    "BUCKET_DIRPATH: str = \"\"\n",
    "OUTPUT: str = \"shap_vals_and_stats\"\n",
    "target_y = 'studyID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GENES = 935\n",
    "N_CLASSES = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_NAME != \"\":\n",
    "    RUN_NAME = RUN_NAME + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import os\n",
    "import joblib\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "#from pyprojroot.here import here\n",
    "from tqdm.auto import trange, tqdm\n",
    "from more_itertools import roundrobin\n",
    "from numba import njit, prange\n",
    "import sparse as sp\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(\n",
    "    here(f'03_downstream_analysis/08_gene_importance/data/{CELL_TYPE}_adataMerged_SPECTRAgenes.log1p.h5ad'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1_score(y_true, y_pred):\n",
    "    return -f1_score(y_true, y_pred.argmax(1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = joblib.load(here(f'03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/03_xgboost/best_model/{RUN_NAME}{CELL_TYPE}_xgb.json'))\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def find_nonzero(m):\n",
    "    coords = np.nonzero(m)\n",
    "    return coords\n",
    "    \n",
    "def to_sparse(m):\n",
    "    coords = find_nonzero(m)\n",
    "    data = m[coords]\n",
    "    return sp.COO(coords, m[coords], shape=m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weldford:\n",
    "    def __init__(self, shape):\n",
    "        self.count = 0\n",
    "        self.mean = np.zeros(shape)\n",
    "        self.M2 = np.zeros(shape)\n",
    "\n",
    "    @staticmethod\n",
    "    @njit(parallel=True)\n",
    "    def _update(arr, count, mean, M2):\n",
    "        count += 1\n",
    "        delta = arr - mean\n",
    "        mean += delta / count\n",
    "        delta2 = arr - mean\n",
    "        M2 += delta * delta2\n",
    "        return count, mean, M2\n",
    "    \n",
    "    def update(self, arr):\n",
    "        self.count, self.mean, self.M2 = self._update(arr, self.count, self.mean, self.M2)\n",
    "\n",
    "    def update_all(self, arr):\n",
    "        self.count, self.mean, self.M2 = self._update_all(arr, self.count, self.mean, self.M2)\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    @njit(parallel=True)\n",
    "    def _update_all(arr, count, mean, M2):\n",
    "        for idx in range(arr.shape[0]):\n",
    "            a = arr[idx]\n",
    "            count += 1\n",
    "            delta = a - mean\n",
    "            mean += delta / count\n",
    "            delta2 = a - mean\n",
    "            M2 += delta * delta2\n",
    "        return count, mean, M2\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.count < 2:\n",
    "            return np.nan\n",
    "        else:\n",
    "            mean, variance = self.mean, self.M2 / self.count\n",
    "            return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_values_with_stats(xgb, X, outer_batch_size = int(10000), inner_batch_size = 25, target_y=''):\n",
    "    explainer = shap.explainers.TreeExplainer(xgb, feature_perturbation='tree_path_dependant')\n",
    "    \n",
    "    stream_stats = {}\n",
    "    for shap_type in ['shap_values', 'shap_int_values']:\n",
    "        for kind in ['abs', 'raw', 'raw_sum', 'raw_sqsum']:\n",
    "            shape = (N_GENES, N_CLASSES) if shap_type == 'shap_values' else (N_GENES, N_GENES, N_CLASSES)\n",
    "            stream_stats[f\"{shap_type}_{kind}\"] = Weldford(shape=shape)\n",
    "\n",
    "    for batch_idx, oidx in enumerate(tqdm(np.arange(X.shape[0], step=outer_batch_size))):\n",
    "\n",
    "        outer_batch_size_fix = min(outer_batch_size, X.shape[0] - oidx)\n",
    "        obatch_shap_vals = []\n",
    "        for iidx in tqdm(np.arange(outer_batch_size_fix, step=inner_batch_size)):\n",
    "\n",
    "            shap_type = 'shap_int_values'\n",
    "            batch_shap_int_vals = explainer.shap_interaction_values(X[oidx+iidx:oidx+iidx+inner_batch_size])\n",
    "            \n",
    "            stream_stats[f'{shap_type}_raw'].update_all(batch_shap_int_vals)\n",
    "            abs_batch_shap_int_vals = np.abs(batch_shap_int_vals)\n",
    "            stream_stats[f'{shap_type}_abs'].update_all(abs_batch_shap_int_vals)\n",
    "            \n",
    "            shap_type = 'shap_values'\n",
    "            batch_shap_vals = batch_shap_int_vals.sum(1)\n",
    "            stream_stats[f'{shap_type}_raw'].update_all(batch_shap_vals)\n",
    "            abs_batch_shap_vals = np.abs(batch_shap_vals)\n",
    "            stream_stats[f'{shap_type}_abs'].update_all(abs_batch_shap_vals)\n",
    "\n",
    "            obatch_shap_vals.append(batch_shap_vals)\n",
    "\n",
    "        # Concatenate sparse\n",
    "        obatch_shap_vals = np.concatenate(obatch_shap_vals)\n",
    "\n",
    "        np.savez_compressed(\n",
    "            here(f'03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/shap/shap_vals/fix_{RUN_NAME}{CELL_TYPE}_shap_values_{batch_idx}'), \n",
    "            shap_values=obatch_shap_vals)\n",
    "\n",
    "    shap_type = 'shap_int'\n",
    "    mean_raw, var_raw = stream_stats[f'{shap_type}_raw'].finalize()\n",
    "    mean_abs, var_abs = stream_stats[f'{shap_type}_abs'].finalize()\n",
    "    np.savez_compressed(\n",
    "        here(f'03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/shap/shap_vals/total_{RUN_NAME}{CELL_TYPE}_{shap_type}_stats.npz'), \n",
    "        mean_raw=mean_raw, var_raw=var_raw, mean_abs=mean_abs, var_abs=var_abs)\n",
    "    \n",
    "    shap_type = 'shap'\n",
    "    mean_raw, var_raw = stream_stats[f'{shap_type}_raw'].finalize()\n",
    "    mean_abs, var_abs = stream_stats[f'{shap_type}_abs'].finalize()\n",
    "    np.savez_compressed(\n",
    "        here(f'03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/shap/shap_vals/total_{RUN_NAME}{CELL_TYPE}_{shap_type}_stats.npz'), \n",
    "        mean_raw=mean_raw, var_raw=var_raw, mean_abs=mean_abs, var_abs=var_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_shap_interaction_values(xgb, X, sorted_idxs, outer_batch_size = int(500), inner_batch_size = 25, n_instances: int = 10000, target_y=target_y):\n",
    "    explainer = shap.explainers.TreeExplainer(xgb, feature_perturbation='tree_path_dependant')\n",
    "    for obatch_idx in trange(int(n_instances // outer_batch_size)):\n",
    "        # Compute outer idx\n",
    "        oidx = int(outer_batch_size * obatch_idx)\n",
    "\n",
    "        shap_coo = []\n",
    "        for iidx in range(0, outer_batch_size, inner_batch_size):\n",
    "            selected_idxs = sorted_idxs[oidx+iidx:oidx+iidx+inner_batch_size]\n",
    "            shap_coo.append(to_sparse(explainer.shap_interaction_values(X[selected_idxs])))\n",
    "\n",
    "        # Concatenate sparse\n",
    "        shap_coo = sp.concatenate(shap_coo)\n",
    "\n",
    "        # Save batch\n",
    "        sp.save_npz(here(f'03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/shap/{RUN_NAME}{CELL_TYPE}_shap_int_{obatch_idx}.npz'), shap_coo)\n",
    "\n",
    "        print(f\"BATCH {obatch_idx} DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(here(f\"03_downstream_analysis/08_gene_importance/results/targetY_{target_y}/shap/shap_vals/\"), exist_ok=True)\n",
    "\n",
    "if OUTPUT==\"shap_vals_and_stats\":\n",
    "    compute_shap_values_with_stats(xgb, adata.X, target_y=target_y)\n",
    "elif OUTPUT==\"shap_int\":\n",
    "    patient_roundrobin = list(roundrobin(*adata.obs.groupby('sampleID').indices.values()))\n",
    "    np.save(here(f'03_downstream_analysis/08_gene_importance/results/{target_y}/shap/{RUN_NAME}{CELL_TYPE}_patient_roundrobin.npy'), patient_roundrobin)\n",
    "    compute_and_save_shap_interaction_values(xgb, adata.X, sorted_idxs=patient_roundrobin, target_y=target_y)  \n",
    "else:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
